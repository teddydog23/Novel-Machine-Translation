{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "597c39d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079ee330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from model.encoder import Encoder\n",
    "from model.decoder import Decoder\n",
    "from model.seq2seq import Seq2Seq\n",
    "from dataset.preprocess import collate_fn, TranslationDataset\n",
    "\n",
    "from config import *\n",
    "from loss import get_loss, compute_loss\n",
    "from optimizer import get_optimizer, get_plateau_scheduler\n",
    "from early_stopping import EarlyStopping\n",
    "from eval import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d5320b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load data ===\n",
    "data = torch.load(DATA_PATH)\n",
    "src_lines = data[\"src_lines\"]\n",
    "tgt_lines = data[\"tgt_lines\"]\n",
    "vocab_en = data[\"vocab_en\"]\n",
    "vocab_vi = data[\"vocab_vi\"]\n",
    "pad_idx = data[\"pad_idx\"]\n",
    "\n",
    "# === Khá»Ÿi táº¡o láº¡i Dataset\n",
    "train_dataset = TranslationDataset(src_lines[\"train\"], tgt_lines[\"train\"], vocab_en, vocab_vi)\n",
    "val_dataset   = TranslationDataset(src_lines[\"val\"], tgt_lines[\"val\"], vocab_en, vocab_vi)\n",
    "\n",
    "# === Dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          collate_fn=lambda x: collate_fn(x, pad_idx))\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        collate_fn=lambda x: collate_fn(x, pad_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4fb34e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn= lambda x: collate_fn(x, pad_idx)\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn= lambda x: collate_fn(x, pad_idx)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c48d464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(vocab_en)\n",
    "OUTPUT_DIM = len(vocab_vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd36b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Init model ===\n",
    "encoder = Encoder(INPUT_DIM, EMBED_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT).to(DEVICE)\n",
    "decoder = Decoder(EMBED_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT).to(DEVICE)\n",
    "model = Seq2Seq(encoder, decoder).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2340ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loss_fn = get_loss(pad_idx, use_label_smoothing=True)\n",
    "\n",
    "optimizer = get_optimizer(model, LEARNING_RATE)\n",
    "scheduler = get_plateau_scheduler(optimizer, factor=0.5, patience=2)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=PATIENCE, path=CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a75e334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Logging setup ===\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "log_file = f\"train_log_{timestamp}.txt\"\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "log_path = os.path.join(\"logs\", log_file)\n",
    "\n",
    "def log(message):\n",
    "    print(message)\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(message + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e70d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Training function ===\n",
    "def train(model, loader, optimizer, loss_fn, clip, epoch_num):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(loader, desc=f\"ğŸ” Training Epoch {epoch_num}\", leave=False)\n",
    "\n",
    "    for i, (src, trg) in enumerate(progress_bar):\n",
    "        src = src.transpose(0, 1).to(DEVICE)\n",
    "        trg = trg.transpose(0, 1).to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio=TEACHER_FORCING_RATIO)\n",
    "\n",
    "        output = output[1:].reshape(-1, output.shape[-1])\n",
    "        trg = trg[1:].reshape(-1)\n",
    "\n",
    "        loss = compute_loss(output, trg, loss_fn)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        epoch_loss += batch_loss\n",
    "        progress_bar.set_postfix(batch_loss=f\"{batch_loss:.4f}\")\n",
    "\n",
    "    return epoch_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f657b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Decode function for BLEU/METEOR\n",
    "def decode_sequence(seq, idx2word):\n",
    "    return [idx2word.get(idx, \"<UNK>\") for idx in seq if idx2word.get(idx) not in [\"<PAD>\", \"<EOS>\", \"<SOS>\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fc45559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Epoch timing ===\n",
    "def epoch_time(start, end):\n",
    "    elapsed = end - start\n",
    "    return int(elapsed // 60), int(elapsed % 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9945bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Inverse vocab\n",
    "idx2vi = {v: k for k, v in vocab_vi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "946824ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Training started at 2025-05-19_03-07-37\n",
      "ğŸ§  DEVICE: cuda\n",
      "ğŸ“Š Total Epochs: 10 | Batch Size: 32 | Teacher Forcing: 0.5\n",
      "\n",
      "ğŸ“… Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•’ Time: 50m 28s | ğŸ”¥ Train Loss: 5.5492 | âœ… Val Loss: 5.8539\n",
      "\n",
      "ğŸ“… Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•’ Time: 50m 11s | ğŸ”¥ Train Loss: 5.0975 | âœ… Val Loss: 5.7253\n",
      "\n",
      "ğŸ“… Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•’ Time: 49m 44s | ğŸ”¥ Train Loss: 4.9575 | âœ… Val Loss: 5.6614\n",
      "\n",
      "ğŸ“… Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•’ Time: 49m 47s | ğŸ”¥ Train Loss: 4.8865 | âœ… Val Loss: 5.6938\n",
      "\n",
      "ğŸ“… Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•’ Time: 49m 45s | ğŸ”¥ Train Loss: 4.8476 | âœ… Val Loss: 5.6422\n",
      "\n",
      "ğŸ“… Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•’ Time: 49m 44s | ğŸ”¥ Train Loss: 4.8205 | âœ… Val Loss: 5.6642\n",
      "\n",
      "ğŸ“… Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•’ Time: 49m 46s | ğŸ”¥ Train Loss: 4.8106 | âœ… Val Loss: 5.6881\n",
      "\n",
      "ğŸ“… Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•’ Time: 49m 49s | ğŸ”¥ Train Loss: 4.8237 | âœ… Val Loss: 5.6933\n",
      "\n",
      "ğŸ“… Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•’ Time: 49m 53s | ğŸ”¥ Train Loss: 4.7347 | âœ… Val Loss: 5.6285\n",
      "\n",
      "ğŸ“… Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•’ Time: 50m 45s | ğŸ”¥ Train Loss: 4.6947 | âœ… Val Loss: 5.6565\n",
      "âœ… Training complete.\n"
     ]
    }
   ],
   "source": [
    "# === Main training loop ===\n",
    "log(f\"ğŸš€ Training started at {timestamp}\")\n",
    "log(f\"ğŸ§  DEVICE: {DEVICE}\")\n",
    "log(f\"ğŸ“Š Total Epochs: {N_EPOCHS} | Batch Size: {BATCH_SIZE} | Teacher Forcing: {TEACHER_FORCING_RATIO}\")\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    log(f\"\\nğŸ“… Epoch {epoch + 1}/{N_EPOCHS}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_loader, optimizer, loss_fn, CLIP, epoch + 1)\n",
    "    val_loss = evaluate(model, val_loader, loss_fn, device=DEVICE)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    mins, secs = epoch_time(start_time, time.time())\n",
    "\n",
    "    log(f\"ğŸ•’ Time: {mins}m {secs}s | ğŸ”¥ Train Loss: {train_loss:.4f} | âœ… Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        log(\"â›” Early stopping triggered!\")\n",
    "        break\n",
    "\n",
    "log(\"âœ… Training complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
